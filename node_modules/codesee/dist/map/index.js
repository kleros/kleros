"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.runMap = exports.CONTINUE_EXIT_CODE = void 0;
const axios_1 = __importDefault(require("axios"));
const chalk_1 = __importDefault(require("chalk"));
const commander_1 = __importDefault(require("commander"));
const fs_1 = require("fs");
const domain_core_1 = require("@codesee/domain-core");
const fs_2 = require("../utils/fs");
const constants_1 = require("./constants");
const git_1 = require("./git");
const groups_1 = require("./groups");
const langs_1 = __importDefault(require("./langs"));
const git_2 = require("../utils/git");
const path_1 = __importDefault(require("path"));
const helpers_1 = require("./langs/helpers");
const env_1 = __importDefault(require("../utils/env"));
exports.default = register;
// These constants are conditional over
// CODESEE_USE_REAL_EXIT_CODES so that we can maintain the
// functionality of silent errors in places where we need to
// always succeed like GitHub Actions.
exports.CONTINUE_EXIT_CODE = env_1.default.withExitCodes ? 1 : 0;
const LANGUAGES_FAILED_BUT_CONTINUING_EXIT_CODE = env_1.default.withExitCodes ? 199 : 0; // Yup, this is completely arbitrary.
function register(program) {
    program
        .command("map")
        .description("generate the data for a dependency map")
        .arguments("[repoRoot]")
        .option("-a, --apiToken <token>", "API key for communicating with the server")
        .addOption(new commander_1.default.Option("--forceFull", "force generation of full dependency map").conflicts(["forceIncremental"]))
        .addOption(new commander_1.default.Option("--forceful", "Alias for --forceFull").conflicts("forceIncremental"))
        .addOption(new commander_1.default.Option("--forceIncremental", "force generation of a partial dependency map"))
        .option("-l, --languages <languages>", 'a stringified object of languages (e.g. \'{"javascript":true,"python":false}\')', (value) => {
        // Parse the passed in value as JSON.
        try {
            return JSON.parse(value);
        }
        catch (err) {
            // If they passed in an invalid value for languages, print a warning
            // and assume no languages were passed in.
            console.error(`\n${chalk_1.default.yellow(`Warning: Error parsing languages (${value}). Continuing with no languages provided.`)}`);
            return undefined;
        }
    })
        .addOption(new commander_1.default.Option("-m, --mode <mode>", "map generation mode")
        .choices(["full", "incremental", "infer"])
        .default("infer")
        .conflicts(["forceful", "forceFull", "forceIncremental"]))
        .option("-o, --output <outputFilename>", "File to write")
        .option("-r, --repo <repository>", "The repo origin we are generating the map for. Needed for incremental mode")
        .option("-s, --sandbox", "Whether to generate dependencies within a process sandbox. Must have nsjail installed and functional", false)
        .option("-t, --typescript", "Support Typescript (deprecated, ignored)")
        .option("-u, --url <server>", "url for the codesee instance", "https://app.codesee.io")
        .option("-w, --webpack <config>", "Path to your webpack config relative to your package.json")
        .option("-x, --exclude-lang <excludeLang>", "a comma separated list of languages to exclude from this run")
        .action(map);
}
async function map(...args) {
    try {
        const exitCode = await runMap(args);
        process.exit(exitCode);
    }
    catch (err) {
        const error = err;
        console.error(`\n${chalk_1.default.red(`Error: ${error.message}`)}`);
        console.error(error.stack);
        process.exit(1);
    }
}
async function runMap(args) {
    const repoDir = args[0] || (await fs_2.getCurrentDirectory());
    const opts = args[1];
    opts.mode = opts.forceFull || opts.forceful ? "full" : opts.mode;
    opts.mode = opts.forceIncremental ? "incremental" : opts.mode;
    const excludeLang = (opts.excludeLang || "")
        .toLowerCase()
        .split(",")
        .map((s) => s.trim())
        .filter((s) => s !== "");
    const filteredLangSpecs = langs_1.default.specs.filter((s) => !excludeLang || !excludeLang.includes(s.name));
    // Check that the directory that was passed in exists.
    // This only checks the existence. If we do not have read
    // access, then it will fail downstream returning a more
    // specific error related to what we do no have read permissions
    // on
    if (!(await fs_2.canAccess(repoDir))) {
        const message = `Unable to find ${repoDir}`;
        console.log(`\n${chalk_1.default.red(message)}`);
        return exports.CONTINUE_EXIT_CODE;
    }
    const repoRoot = await git_2.determineRepoRoot(repoDir);
    console.log(chalk_1.default.gray(`found repo root ${repoRoot} from ${repoDir}`));
    const config = await tryLoadConfigFromFile(repoRoot);
    const { mode, previousDependencyMapCommit, fileChangeSet, linkLanguages, packageNamePathLanguages, previousDependencyMapVersion, previousPackageNamePaths, } = await preflightMode(opts, config === null || config === void 0 ? void 0 : config.filenamesThatTriggerFullMap);
    opts.mode = mode;
    opts.packageNamePathLanguages = packageNamePathLanguages;
    opts.previousDependencyMapCommit = previousDependencyMapCommit;
    opts.fileChangeSet = fileChangeSet;
    opts.previousDependencyMapVersion = previousDependencyMapVersion;
    opts.previousPackageNamePaths = previousPackageNamePaths;
    const allFileRootRelPaths = await git_1.runLsTreeForPackage(repoRoot, repoRoot);
    const options = { ...opts, mode };
    // it's safe (currently) to run this even on excluded languages
    // since it only filters the all-files list
    const packageDirsBySpec = await git_1.enumeratePackages(langs_1.default.specs, repoRoot, allFileRootRelPaths, options);
    // If any excluded language found packages, abort!
    // We don't want to produce a dependency map with missing data / links
    const abort = didAnyExcludedLanguagesFindPackages(excludeLang, packageDirsBySpec);
    if (abort) {
        const message = `Found Excluded Languages, Aborting`;
        console.log(`\n${chalk_1.default.red(message)}`);
        return exports.CONTINUE_EXIT_CODE;
    }
    const commitHash = await git_2.getCommitHash(repoRoot);
    const languageOutputs = [];
    const languageSuccesses = new Map();
    for (const spec of filteredLangSpecs) {
        try {
            const languageOptions = {
                ...options,
                // For each language, only possibly generate an incremental map if the
                // previous dependency map has generated links for this language before.
                // If not, then we might have just added support for this new language,
                // so we should generate a full map to get all possible links instead of
                // just looking at modified files.
                mode: (linkLanguages === null || linkLanguages === void 0 ? void 0 : linkLanguages[spec.name]) ? options.mode : "full",
            };
            // It's possible to request an incremental map for a language that doesn't
            // yet support it (i.e. the language-specific dependency doesn't allow for
            // getting the links of a specific file). If that happens, that language
            // will still generate links for all files, but the map will be labeled as
            // "incremental". This doesn't cause any harm because it will just have
            // all the links instead of a subset, but it could get confusing if you
            // see that mode is incremental, but all the links are present.
            const { result: langData, success } = await spec.runForPackages(repoRoot, packageDirsBySpec[spec.name], languageOptions, config[spec.name] || {});
            languageOutputs.push(langData);
            languageSuccesses.set(spec.name, success);
        }
        catch (error) {
            console.log(chalk_1.default.redBright(`${spec.name} threw an error when attempting to run. Please contact support@codesee.io so we can repair this issue.`));
            console.log(error);
        }
    }
    const outputs = languageOutputs.filter((v) => v);
    let output;
    if (outputs.length === 0) {
        output = await runWithoutPackage(repoRoot, options);
        // We remove this because it's only needed in the case of monorepos when we need to merge the results from the
        // individual packages into a mega-diagram. Since packageDirectory isn't part of schema, we want to make sure it
        // doesn't end up in the output
        delete output.packageDirectory;
        groups_1.generateMissingGroups(output.nodes);
    }
    else {
        output = outputs.reduce((previousValue, currentValue) => {
            previousValue.linkLanguages = {
                ...previousValue.linkLanguages,
                ...currentValue.linkLanguages,
            };
            previousValue.packageNamePathLanguages = {
                ...previousValue.packageNamePathLanguages,
                ...currentValue.packageNamePathLanguages,
            };
            previousValue.packageNamePaths.push(...currentValue.packageNamePaths);
            previousValue.nodes.push(...currentValue.nodes);
            previousValue.links.push(...currentValue.links);
            return previousValue;
        });
        // Since we enumerate files for every language, there's a very good chance
        // we have duplicate files defined in nodes. This dedupes them based on the
        // node key.
        // TODO: Can we be smarter here about how we pick the duplicate to keep?
        const nodeSet = new Set();
        const dedupedNodes = [];
        output.nodes.forEach((node) => {
            if (!nodeSet.has(node.key)) {
                dedupedNodes.push(node);
                nodeSet.add(node.key);
            }
        });
        // Add in any files that we've missed completely
        const extraNodes = [];
        allFileRootRelPaths.forEach((filePath) => {
            if (!nodeSet.has(filePath)) {
                // don't add to nodeSet yet! need to make groups first
                extraNodes.push({
                    key: filePath,
                });
            }
        });
        groups_1.generateMissingGroups(extraNodes);
        extraNodes.forEach((node) => {
            if (!nodeSet.has(node.key)) {
                nodeSet.add(node.key);
                dedupedNodes.push(node);
            }
        });
        output.nodes = dedupedNodes;
    }
    // Regardless of whether every language supports incremental, we prune the
    // list of nodes to only be those touched in the differential if it's being
    // run in incremental mode. The server will reconstruct the correct list of
    // nodes and it allows us to send less data across the wire.
    if (mode === "incremental" && options.fileChangeSet) {
        const filesToProcessSet = helpers_1.getFilesToProcessFromFileChangeSet(options.fileChangeSet);
        // We only filter out nodes and not links because each language should be
        // able to determine if new links need to be added. Worst case, if a
        // language doesn't support incremental, we'll just include all links, but
        // that won't cause any issues in terms of data correctness.
        output.nodes = output.nodes.filter((node) => filesToProcessSet.has(node.key));
        // We just filtered out everything that's not a file, so we need to
        // regenerate the missing groups.
        groups_1.generateMissingGroups(output.nodes);
    }
    // There is only one commitHash which we gathered at the beginning
    // before the languages ran.
    output.commitHash = commitHash;
    // ENG-769: Ensure that version is always present.
    output.version = constants_1.fileFormatVersion4;
    // ENG-758: Ensure that, if anything ran incrementally, we report
    // mode as incremental, and include the data needed to compute
    // a full map from an incremental map. Note that we should *not*
    // be using the value of linkLanguages from the previous map
    // below.
    output.mode = mode;
    output.previousDependencyMapCommit = previousDependencyMapCommit;
    output.fileChangeSet = fileChangeSet;
    output = await cleanupOutput(output, repoRoot);
    const strData = JSON.stringify(output);
    if (opts.output) {
        await fs_1.promises.writeFile(opts.output, strData);
    }
    else {
        console.log(strData);
    }
    let exitCode = 0;
    languageSuccesses.forEach((success, lang) => {
        if (!success) {
            console.warn(`${lang} was not successful`);
            exitCode = LANGUAGES_FAILED_BUT_CONTINUING_EXIT_CODE;
        }
    });
    return exitCode;
}
exports.runMap = runMap;
async function runWithoutPackage(repoRoot, options) {
    const promises = await Promise.all([
        git_2.getCommitHash(repoRoot),
        git_1.enumerateFiles(repoRoot, repoRoot, constants_1.exclusions, []),
    ]);
    const results = {
        version: constants_1.fileFormatVersion4,
        mode: (options === null || options === void 0 ? void 0 : options.mode) || "full",
        linkLanguages: {},
        packageNamePathLanguages: {},
        packageName: undefined,
        packageDirectory: "",
        packageNamePaths: [],
        commitHash: promises[0],
        previousDependencyMapCommit: options === null || options === void 0 ? void 0 : options.previousDependencyMapCommit,
        fileChangeSet: options === null || options === void 0 ? void 0 : options.fileChangeSet,
        configuration: "",
        nodes: promises[1].map((n) => ({ key: n })),
        links: [],
    };
    return results;
}
async function preflightMode(opts, additionalFilenamesThatTriggerFullMap = []) {
    const { apiToken, languages: detectedLanguages, mode, repo } = opts;
    let previousDependencyMapCommit;
    let fileChangeSet = null;
    let linkLanguages;
    let packageNamePathLanguages;
    let previousDependencyMapVersion;
    let previousPackageNamePaths = [];
    if (mode === "full") {
        return { mode: "full" };
    }
    if (apiToken === undefined ||
        detectedLanguages === undefined ||
        repo === undefined) {
        console.log(chalk_1.default.yellowBright("apiToken, languages, or repo were not provided\nMust generate full dependency map"));
        return { mode: "full" };
    }
    const endpoint = `${opts.url}/api/maps/repos/${encodeURIComponent(repo)}/dependency_map/metadata/latest`;
    const headers = { Authorization: `Bearer ${apiToken}` };
    try {
        const response = await axios_1.default({
            url: endpoint,
            method: "GET",
            headers,
            withCredentials: true,
        });
        previousDependencyMapCommit = response.data.gitCommit;
        linkLanguages = response.data.linkLanguages;
        packageNamePathLanguages = response.data.packageNamePathLanguages;
        previousDependencyMapVersion = response.data.version;
        previousPackageNamePaths = response.data.packageNamePaths || [];
    }
    catch (err) {
        if (axios_1.default.isAxiosError(err) && err.response) {
            if (err.response.status === 404) {
                console.log(chalk_1.default.whiteBright("Previous dependency map metadata not found\nGenerating full dependency map"));
            }
            else {
                console.error(chalk_1.default.yellowBright(`Received HTTP response with status code ${err.response.status} fetching previous dependency map metadata\nGenerating full dependency map`));
            }
        }
        else {
            console.error(chalk_1.default.red(`Error fetching previous dependency map metadata: ${err}\nGenerating full dependency map`));
        }
        return { mode: "full" };
    }
    if (previousDependencyMapCommit) {
        fileChangeSet = await git_2.determineFileChangeSet(git_2.getBaseRemote(), previousDependencyMapCommit);
        if (fileChangeSet) {
            const filesToProcessSet = helpers_1.getFilesToProcessFromFileChangeSet(fileChangeSet, true);
            const additionalFilenamesThatTriggerFullMapSet = new Set(...additionalFilenamesThatTriggerFullMap);
            const filesInRepoThatTriggerFullMap = [...filesToProcessSet].filter((f) => {
                const filename = path_1.default.basename(f);
                return (constants_1.filenamesThatTriggerFullMapSet.has(filename) ||
                    additionalFilenamesThatTriggerFullMapSet.has(filename));
            });
            if (filesInRepoThatTriggerFullMap.length > 0) {
                console.log(chalk_1.default.whiteBright(`Detected changes to the following files that require a full dependency map build:\n${JSON.stringify(filesInRepoThatTriggerFullMap, null, 2)}`));
                return { mode: "full" };
            }
        }
    }
    if (!fileChangeSet || !previousDependencyMapCommit) {
        return { mode: "full" };
    }
    console.log(chalk_1.default.greenBright(`Attempting to generate an incremental dependency map.`));
    return {
        mode: "incremental",
        previousDependencyMapCommit,
        fileChangeSet,
        linkLanguages,
        packageNamePathLanguages,
        previousDependencyMapVersion,
        previousPackageNamePaths,
    };
}
/**
 * cleanupOutput does some final cleanup on the intermediate output we get
 * from running each of the language bindings.
 *
 * @param {MergeResultV4} results - intermediate results output from running
 *   language bindings
 * @param {string} repoRoot - absolute path to repo root
 *
 * @returns {Promise<MergeResultV4>} - cleaned up copy of results with
 *   non-existent nodes and links pruned, and after
 *   TODO: ENG-612 nodes and links sorted.
 */
async function cleanupOutput(results, repoRoot) {
    const cleaned = await pruneNonExistentEntries(results, repoRoot);
    // TODO: ENG-612: This is where we would add calls to
    // sortNodes and sortLinks which are in @codesee/domain-core:
    // cleaned.nodes = sortNodes(cleaned.nodes);
    // cleaned.links = sortLinks(cleaned.links);
    cleaned.packageNamePaths = domain_core_1.sortPackageNamePaths(cleaned.packageNamePaths);
    return cleaned;
}
/**
 * pruneNonExistentEntries checks that the files associated with each
 * node and link exist, and removes nodes and links that reference
 * non-existent files.
 *
 * @param {MergeResultV4} results - intermediate results output from running
 *   language bindings
 *
 * @returns {Promise<MergeResultV4>} - copy of results with non-existent
 *   nodes and links referencing non-existent files removed.
 */
async function pruneNonExistentEntries(results, repoRoot) {
    // ENG-838: We sometimes make changes to the index of the
    // repository after checking out its contents. In particular,
    // if a repository has an `.npmrc` file, we delete it because
    // it interferes with our ability to run the CodeSee CLI via
    // npx. The changes to the index should not influence the
    // data we output in the dependency map. The easiest way to
    // undo all changes is to execute `git stash save`, so that's
    // what we do.
    await git_1.stashSave(repoRoot);
    // We use runLsTreeForPackage here instead of enumerateFiles because that
    // returns the canonical list of files that are expected to be included in the
    // dependency map.
    const onlyFiles = await git_1.runLsTreeForPackage(repoRoot, repoRoot);
    const filesAndDirectories = groups_1.createSetWithFilesAndDirectories(new Set(onlyFiles));
    const validResult = {
        ...results,
        nodes: [],
        links: [],
    };
    for (const node of results.nodes) {
        if (node.key && filesAndDirectories.has(node.key)) {
            validResult.nodes.push(node);
        }
    }
    for (const { from, to } of results.links) {
        if (from &&
            to &&
            filesAndDirectories.has(from) &&
            filesAndDirectories.has(to)) {
            validResult.links.push({ from, to });
        }
    }
    if (validResult.nodes.length != results.nodes.length) {
        console.error(`\n${chalk_1.default.yellow(`Warning: Pruned ${results.nodes.length - validResult.nodes.length} nodes referencing files that don't exist from intermediate output.`)}`);
    }
    if (validResult.links.length != results.links.length) {
        console.error(`\n${chalk_1.default.yellow(`Warning: Pruned ${results.links.length - validResult.links.length} links referencing files that don't exist from intermediate output.`)}`);
    }
    try {
        // ENG-838: Before this function completes, we must restore
        // the changes to the index by executing `git stash pop` to
        // pop the saved stash entry.
        await git_1.stashPop(repoRoot);
    }
    catch (e) {
        // No-op
        // This catch block exists because `git stash pop` will
        // fail and throw if no stash entry exists because the
        // index was unmodified, which might happen if a repository
        // does not contain a `.npmrc` file.
    }
    return validResult;
}
function didAnyExcludedLanguagesFindPackages(excludeLang, packageDirsBySpec) {
    var _a;
    if (excludeLang.length > 0) {
        console.log(chalk_1.default.redBright(`There are excluded languages in this environment: ${JSON.stringify(excludeLang)}`));
        for (const foundLang of excludeLang) {
            // If someone puts an unknown language in the exclude
            // list, we will not have a packageDirsBySpec entry
            // for them, so we can assume that there are 0
            // packages because we don't support that language. If
            // we did support it, there would at least be an entry
            // in the map
            const packageCount = ((_a = packageDirsBySpec[foundLang]) === null || _a === void 0 ? void 0 : _a.length) || "0";
            console.log(chalk_1.default.redBright(`${foundLang} has ${packageCount} packages`));
            if (excludeLang.includes(foundLang) && packageCount > 0) {
                // abort!
                console.log(chalk_1.default.redBright(`We must abort to avoid running excluded language spec.`));
                return true;
            }
        }
    }
    return false;
}
async function tryLoadConfigFromFile(repoDir) {
    const configFileAbsPath = path_1.default.join(repoDir, ".codesee.json");
    if (!fs_2.canAccessSync(configFileAbsPath)) {
        return {};
    }
    try {
        const contents = await fs_1.promises.readFile(configFileAbsPath, "utf8");
        const config = JSON.parse(contents);
        return config;
    }
    catch (error) {
        console.log(chalk_1.default.yellowBright(`Unable to read config file at ${configFileAbsPath}`), error);
    }
}
